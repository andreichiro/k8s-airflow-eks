--
c6g.4xlarge	
efs id:
fs-074b0526db14cdee8

cluster name:
aws eks --region us-east-1 update-kubeconfig --name h2-lakehouse-on-k8s-eks
-
aws eks --region us-east-1 update-kubeconfig --name h2-lakehouse-on-k8s-eks
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 003422509138.dkr.ecr.us-east-1.amazonaws.com

docker build -t airflow-custom:v1.5 .

docker tag 5319b86401cb 003422509138.dkr.ecr.us-east-1.amazonaws.com/airflow-custom:v1.5
docker push 003422509138.dkr.ecr.us-east-1.amazonaws.com/airflow-custom:v1.5
-
Tags 
aws:cloudformation:stack-name	eksctl-h2-lakehouse-on-k8s-eks-nodegroup-lakehouse-on-k8s-demand

alpha.eksctl.io/cluster-name	h2-lakehouse-on-k8s-eks
alpha.eksctl.io/nodegroup-name	lakehouse-on-k8s-demand
karpenter.sh/discovery	h2-lakehouse-on-k8s-eks
aws:cloudformation:stack-id	arn:aws:cloudformation:us-east-1:003422509138:stack/eksctl-h2-lakehouse-on-k8s-eks-nodegroup-lakehouse-on-k8s-demand/2d771020-91e5-11ee-b572-0e2c11b2ce3f
eksctl.cluster.k8s.io/v1alpha1/cluster-name	h2-lakehouse-on-k8s-eks
aws:cloudformation:logical-id	ManagedNodeGroup
alpha.eksctl.io/nodegroup-type	managed
alpha.eksctl.io/eksctl-version	0.164.0
nodegroup-role	managed_node_group


-
eksctl create cluster -f cluster/cluster.yaml

helm install argocd -n argocd argo/argo-cd --set redis-ha.enabled=true --set controller.replicas=2 --set server.autoscaling.enabled=true --set server.autoscaling.minReplicas=2 --set repoServer.autoscaling.enabled=true --set repoServer.autoscaling.minReplicas=2 --set applicationSet.replicaCount=2 --set server.service.type=LoadBalancer --create-namespace

kubectl apply -f argoCD\deployment.yaml                                                                                      

kubectl create secret generic airflow-redis-secret --from-literal=password='dados123456' -n airflow
kubectl create secret generic broker-secret --from-literal=connection='redis://:dados123456@airflow-redis.airflow.svc.cluster.local:6379/0' -n airflow
kubectl apply -f airflow\chart\config-map-secrets\airflow-secret.yaml
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" 

base64 -> RVdnaHM0c2ZuQWVnVGxDRw==
EWghs4sfnAegTlCG
-
kubectl delete pods --field-selector=status.phase=Failed -n airflow
kubectl get svc -n argocd
-
-----BEGIN OPENSSH PRIVATE KEY-----
b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW
QyNTUxOQAAACDjswEsSotQWoR5/1roMHNTQuSJWD6GOnVyv0ZIjGjv3AAAAJgaqwwrGqsM
KwAAAAtzc2gtZWQyNTUxOQAAACDjswEsSotQWoR5/1roMHNTQuSJWD6GOnVyv0ZIjGjv3A
AAAEAz+rVvXz3EbtxUqaKbQ2iqszKbk5cbc/ZZRW40ZDOyEeOzASxKi1BahHn/Wugwc1NC
5IlYPoY6dXK/RkiMaO/cAAAAFWFuZHJlaWNoaXJvQGdtYWlsLmNvbQ==
-----END OPENSSH PRIVATE KEY-----

ssh-keyscan github.com

kubectl logs airflow-scheduler-7d7f564869-j95zz -c git-sync-init -n airflow
-

eksctl upgrade cluster -f config/cluster.yaml                                                                             
eksctl upgrade nodegroup --cluster h2-lakehouse-on-k8s-eks --name lakehouse-on-k8s-demand --region us-east-1
-

choco install jq -y

choco install curl -y

Invoke-WebRequest -Uri "https://api.cast.ai/v1/agent.yaml?provider=eks" -Headers @{"Authorization"="Token de1426c717a267c8ec843afd4795bfac487a360f7eeedc247c6ae164c4aad4cd"} | Select-Object -ExpandProperty Content | kubectl apply -f -

/bin/bash -c "$(curl -fsSL 'https://api.cast.ai/v1/scripts/eks/onboarding.sh')"


export CASTAI_API_TOKEN="8fbd3bbe016ac9f495f329dbd30c14a44a1308468dfed6d98676c1c77819fdf7"
export CASTAI_CLUSTER_ID="cbd5b4bd-e18b-499d-a9bc-b4281b5dfbd9"
export CLUSTER_NAME="h2-lakehouse-on-k8s-eks"
export INSTALL_KVISOR=$true
export REGION="us-east-1"
export USER_ARN="arn:aws:iam::809060229965:user/cast-crossrole-cbd5b4bd-e18b-499d-a9bc-b4281b5dfbd9"

curl -fsSL 'https://api.cast.ai/v1/scripts/eks/onboarding.sh' | bash

-

redis:
  existingSecret: "airflow-redis-password"

kubectl port-forward svc/airflow-webserver 8080:8080 -n airflow

---

 eksctl create iamidentitymapping --cluster h2-lakehouse-on-k8s-eks --namespace emr-eks --service-name "emr-containers"

aws emr-containers create-virtual-cluster --name emr_eks_cluster --container-provider '{
    "id":   "h2-lakehouse-on-k8s-eks",
    "type": "EKS",
    "info": {
        "eksInfo": {
            "namespace": "emr-eks"
        }
    }
}'

aws emr-containers update-role-trust-policy \
       --cluster-name h2-lakehouse-on-k8s-eks \
       --namespace emr-eks \
       --role-name EMR_DefaultRole


------------

kubectl create namespace starburst-enterprise
            
eksctl create iamserviceaccount --name starburst-enterprise-sa --namespace starburst-enterprise --cluster h2-lakehouse-on-k8s-eks --attach-policy-arn arn:aws:iam::aws:policy/AWSMarketplaceMeteringFullAccess --attach-policy-arn arn:aws:iam::aws:policy/AWSMarketplaceMeteringRegisterUsage --attach-policy-arn arn:aws:iam::aws:policy/service-role/AWSLicenseManagerConsumptionPolicy --approve

export HELM_EXPERIMENTAL_OCI=1

aws ecr get-login-password --region us-east-1 | helm registry login --username AWS --password-stdin 709825985650.dkr.ecr.us-east-1.amazonaws.com

mkdir awsmp-chart && cd awsmp-chart

helm pull oci://709825985650.dkr.ecr.us-east-1.amazonaws.com/starburst/starburst-enterprise-helm-chart-paygo --version 423.6.0-aws.108

tar xf $(pwd)/* && find $(pwd) -maxdepth 1 -type f -delete

helm install starburst-enterprise --namespace starburst-enterprise ./* 

--

kubectl apply -f https://raw.githubusercontent.com/kubernetes/autoscaler/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-autodiscover.yaml
kubectl -n kube-system annotate deployment.apps/cluster-autoscaler cluster-autoscaler.kubernetes.io/safe-to-evict="false"
kubectl -n kube-system edit deployment.apps/cluster-autoscaler

- --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/CLUSTERNAME
- --balance-similar-node-groups
- --skip-nodes-with-system-pods=false

kubectl -n kube-system set image deployment.apps/cluster-autoscaler cluster-autoscaler=us.gcr.io/k8s-artifacts-prod/autoscaling/cluster-autoscaler:v1.28.1

---
-

